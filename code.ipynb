{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlba_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXnMLoCUw9uo",
        "outputId": "ddbc721a-b121-4243-b556-af356b794719"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ML datasets'\n",
        "%ls\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/ML datasets\n",
            " abalone.data    DT-B-2-CC.png             mbti_1.csv          output_MLP.csv\n",
            " data_1.csv      DT-B-2-XX.png             output_cnn.csv      output_svm.csv\n",
            " data_2.csv      DT_C_1.pkl                output.csv         'ROC Curve.png'\n",
            " diabetes2.csv   fashion-mnist_test.csv    output_forest.csv   test_data.csv\n",
            " DT_A_1.png      fashion-mnist_train.csv   output_knn.csv      train_data.csv\n",
            " DT_B_1.png      imagename.png             output_log.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjZN-U56v1tx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb40bc14-2ecd-4e05-b860-8ebf9ad210c7"
      },
      "source": [
        "#install packages\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->imbalanced-learn) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2EG27H0wp2h"
      },
      "source": [
        "#loading the training dataset\n",
        "data=pd.read_csv('train_data.csv')\n",
        "\n",
        "#loading the testing dataset\n",
        "data_test=pd.read_csv('test_data.csv')\n",
        "\n",
        "#storing IDs from testing dataset\n",
        "test_data_id= []\n",
        "for id,seq in zip(data_test['ID'], data_test['Sequence']):\n",
        "    test_data_id.append(id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FKogUwaq4ht"
      },
      "source": [
        "#Pre-Processing\n",
        "\n",
        "#Feature Extraction\n",
        "#Function to Add Features: Integer Encoding, Binary Profiling, Molecular_weight\n",
        "char_dict= {'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20}\n",
        "molecular_weight_dict={\"X\":0,\"A\":89.1,\"R\":174.2,\"N\":132.1,\"D\":133.1,\"C\":121.2,\"E\":147.1,\"Q\":146.2,\"G\":75.1,\"H\":155.2,\"I\":131.2,\"L\":131.2,\"K\":146.2,\"M\":149.2,\"F\":165.2,\"P\":115.1,\"S\":105.1,\"T\":119.1,\"W\":204.2,\"Y\":181.2,\"V\":117.1}\n",
        "distinct_genes='ACDEFGHIKLMNPQRSTVWXY'\n",
        "def feature_extraction(data):\n",
        "  encode_list = []\n",
        "  for row in data['Sequence'].values:\n",
        "    row_encode = []\n",
        "    temp_array=[]\n",
        "    weight=0\n",
        "    for d in distinct_genes:\n",
        "      temp_array.append(row.count(d))\n",
        "    for code in row:\n",
        "      row_encode.append(char_dict.get(code, 0))\n",
        "      gene_string=[0 for k in range(21)]\n",
        "      # print(i)\n",
        "      gene_string[distinct_genes.index(code)]=1\n",
        "      temp_array.extend(gene_string)\n",
        "      # if not molecular_weight_dict.get(code):print(code)\n",
        "      weight+=molecular_weight_dict.get(code)\n",
        "    row_encode.extend(temp_array)\n",
        "    row_encode.append(weight)\n",
        "    encode_list.append(np.array(row_encode))\n",
        "    # print(row_encode)\n",
        "  return encode_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09lhXFV6sbNS"
      },
      "source": [
        "#Features and Labels splitting\n",
        "X_data = feature_extraction(data)\n",
        "Y_data = data['label'].values\n",
        "X_data_test = feature_extraction(data_test)\n",
        "#print(X_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44acXS9xEnyA"
      },
      "source": [
        "#Sampling:\n",
        "under = RandomUnderSampler(sampling_strategy=0.7)   #Under sampling data to Fix Data imbalance \n",
        "X_data, Y_data = under.fit_resample(X_data, Y_data)\n",
        "#print(Counter(Y_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7HHntT2ErQ6"
      },
      "source": [
        "#Splitting data into train and validation dataset to check accuracy\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_data, Y_data, test_size=0.2, random_state=123,stratify= Y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzEqJWBDNAtU",
        "outputId": "f63f53d6-04a6-40b6-b20e-8a6bb7d384bc"
      },
      "source": [
        "#Best model: RandomForestRegressor\n",
        "\n",
        "print(\"Best model: RandomForestRegressor: \\n\")\n",
        "#min_samples_split=10 and n_estimators=100 to avoid overfitting and underfitting\n",
        "rf = RandomForestRegressor(min_samples_split=10, n_estimators=100, n_jobs=-1) \n",
        "\n",
        "#GridSearchCV to apply  K-fold cross Validation and Hypeparameter tuning\n",
        "grid = GridSearchCV(estimator = rf, param_grid = {}, cv = 10, verbose=2, n_jobs = -1)\n",
        "grid.fit(X_data, Y_data)\n",
        "\n",
        "#Best estimator from GridSearchCV\n",
        "print(grid.best_estimator_)\n",
        "forest= grid.best_estimator_\n",
        "\n",
        "#Predicting values\n",
        "predictions = forest.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],predictions[i]])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: RandomForestRegressor: \n",
            "\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.9min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
            "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_impurity_split=None, min_samples_leaf=1,\n",
            "                      min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
            "                      n_estimators=100, n_jobs=-1, oob_score=False,\n",
            "                      random_state=None, verbose=0, warm_start=False)\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID     Label\n",
            "0     10001  0.258232\n",
            "1     10002  0.256519\n",
            "2     10003  0.199651\n",
            "3     10004  0.420792\n",
            "4     10005  0.300917\n",
            "...     ...       ...\n",
            "9577  19578  0.509828\n",
            "9578  19579  0.730983\n",
            "9579  19580  0.336750\n",
            "9580  19581  0.429539\n",
            "9581  19582  0.393197\n",
            "\n",
            "[9582 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGPTr_lfc4mR",
        "outputId": "2153457d-b5e8-4b65-b5b5-f1eecc0e85e7"
      },
      "source": [
        "#Model: Logistic Regression\n",
        "\n",
        "print(\"Model: Logistic Regression: \\n\")\n",
        "\n",
        "log = LogisticRegression(n_jobs=-1) \n",
        "\n",
        "#GridSearchCV to apply  K-fold cross Validation and Hypeparameter tuning\n",
        "grid = GridSearchCV(estimator = log, param_grid = {}, cv = 10, verbose=2, n_jobs = -1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "#Best estimator from GridSearchCV\n",
        "print(grid.best_estimator_)\n",
        "logistic= grid.best_estimator_\n",
        "\n",
        "#Chceking accuracy on val data\n",
        "Y_pred_val= logistic.predict(X_val)\n",
        "print(\"\\n Classification Report for Validation dataset: \\n\")\n",
        "print(classification_report(Y_val, Y_pred_val))\n",
        "\n",
        "\n",
        "#Predicting values\n",
        "predictions = logistic.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],predictions[i]])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output_log.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression: \n",
            "\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            " Classification Report for Validation dataset: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.83      0.73       515\n",
            "           1       0.59      0.37      0.45       360\n",
            "\n",
            "    accuracy                           0.64       875\n",
            "   macro avg       0.62      0.60      0.59       875\n",
            "weighted avg       0.63      0.64      0.61       875\n",
            "\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID  Label\n",
            "0     10001      0\n",
            "1     10002      1\n",
            "2     10003      0\n",
            "3     10004      0\n",
            "4     10005      0\n",
            "...     ...    ...\n",
            "9577  19578      0\n",
            "9578  19579      1\n",
            "9579  19580      0\n",
            "9580  19581      0\n",
            "9581  19582      0\n",
            "\n",
            "[9582 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ATGYTgTM2xI",
        "outputId": "fcf530ce-19ac-45e6-d9e8-e24c8fc31157"
      },
      "source": [
        "#Model: SVM\n",
        "\n",
        "print(\"Model: SVM: \\n\")\n",
        "svm = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "\n",
        "#training the model\n",
        "svm.fit(X_train, Y_train)\n",
        "\n",
        "#Chceking accuracy on val data\n",
        "Y_pred_val= svm.predict(X_val)\n",
        "print(\"\\n Classification Report for Validation dataset: \\n\")\n",
        "print(classification_report(Y_val, Y_pred_val))\n",
        "\n",
        "#Predicting values\n",
        "predictions = svm.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],int(predictions[i])])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output_svm.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: SVM: \n",
            "\n",
            "\n",
            " Classification Report for Validation dataset: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.92      0.78       515\n",
            "           1       0.76      0.38      0.51       360\n",
            "\n",
            "    accuracy                           0.70       875\n",
            "   macro avg       0.72      0.65      0.65       875\n",
            "weighted avg       0.71      0.70      0.67       875\n",
            "\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID  Label\n",
            "0     10001      0\n",
            "1     10002      0\n",
            "2     10003      0\n",
            "3     10004      0\n",
            "4     10005      0\n",
            "...     ...    ...\n",
            "9577  19578      0\n",
            "9578  19579      1\n",
            "9579  19580      0\n",
            "9580  19581      0\n",
            "9581  19582      1\n",
            "\n",
            "[9582 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZIVeQWo_1IU",
        "outputId": "383a1338-c1d8-47ca-ef13-04ee4328bbe9"
      },
      "source": [
        "#Model: Kth Nearest Neighbour\n",
        "\n",
        "print(\"Model: KNN \\n\")\n",
        "knn = KNeighborsClassifier(n_neighbors=20)\n",
        "\n",
        "#training the model\n",
        "knn.fit(X_train, Y_train)\n",
        "\n",
        "#Chceking accuracy on val data\n",
        "Y_pred_val= knn.predict(X_val)\n",
        "print(\"\\n Classification Report for Validation dataset: \\n\")\n",
        "print(classification_report(Y_val, Y_pred_val))\n",
        "\n",
        "#Predicting values\n",
        "predictions = knn.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],int(predictions[i])])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output_svm.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: KNN \n",
            "\n",
            "\n",
            " Classification Report for Validation dataset: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.89      0.72       515\n",
            "           1       0.48      0.15      0.23       360\n",
            "\n",
            "    accuracy                           0.58       875\n",
            "   macro avg       0.54      0.52      0.47       875\n",
            "weighted avg       0.55      0.58      0.52       875\n",
            "\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID  Label\n",
            "0     10001      0\n",
            "1     10002      0\n",
            "2     10003      1\n",
            "3     10004      0\n",
            "4     10005      0\n",
            "...     ...    ...\n",
            "9577  19578      0\n",
            "9578  19579      1\n",
            "9579  19580      0\n",
            "9580  19581      0\n",
            "9581  19582      0\n",
            "\n",
            "[9582 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EukZ4COBURM",
        "outputId": "73d8d17e-8197-4ea6-e3a1-8429be7207df"
      },
      "source": [
        "#Best model:  RandomForestClassifier\n",
        "\n",
        "print(\"Model:  RandomForestClassifier \\n\")\n",
        "#min_samples_split=10 and n_estimators=100 to avoid overfitting and underfitting\n",
        "rc = RandomForestClassifier(min_samples_split=10, n_estimators=100, n_jobs=-1) \n",
        "\n",
        "#GridSearchCV to apply  K-fold cross Validation and Hypeparameter tuning\n",
        "grid = GridSearchCV(estimator = rc, param_grid = {}, cv = 10, verbose=2, n_jobs = -1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "#Best estimator from GridSearchCV\n",
        "print(grid.best_estimator_)\n",
        "forestc= grid.best_estimator_\n",
        "\n",
        "#Chceking accuracy on val data\n",
        "Y_pred_val= forestc.predict(X_val)\n",
        "print(\"\\n Classification Report for Validation dataset: \\n\")\n",
        "print(classification_report(Y_val, Y_pred_val))\n",
        "\n",
        "\n",
        "#Predicting values\n",
        "predictions = forestc.predict(X_data_test)\n",
        "\n",
        "#Converting output into csv file\n",
        "output_data= []\n",
        "for i in range(len(predictions)):\n",
        "    output_data.append([test_data_id[i],predictions[i]])\n",
        "output_df=pd.DataFrame(output_data,columns=['ID','Label'])\n",
        "output_df.to_csv('output.csv', sep=',', index=False)\n",
        "print(\"\\n Output File: \\n\")\n",
        "print(output_df)\n",
        "print(\"\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model:  RandomForestClassifier \n",
            "\n",
            "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    9.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=10,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "\n",
            " Classification Report for Validation dataset: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.93      0.78       515\n",
            "           1       0.79      0.36      0.49       360\n",
            "\n",
            "    accuracy                           0.69       875\n",
            "   macro avg       0.73      0.64      0.64       875\n",
            "weighted avg       0.72      0.69      0.66       875\n",
            "\n",
            "\n",
            " Output File: \n",
            "\n",
            "         ID  Label\n",
            "0     10001      0\n",
            "1     10002      0\n",
            "2     10003      0\n",
            "3     10004      0\n",
            "4     10005      0\n",
            "...     ...    ...\n",
            "9577  19578      1\n",
            "9578  19579      1\n",
            "9579  19580      0\n",
            "9580  19581      0\n",
            "9581  19582      0\n",
            "\n",
            "[9582 rows x 2 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}